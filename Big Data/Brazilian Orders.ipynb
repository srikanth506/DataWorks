{"cells": [{"cell_type": "markdown", "id": "a8db35ff-40c6-4832-93ae-25583f8aa267", "metadata": {"tags": []}, "source": "## Module 1 - Data Ingestion & Exploration\n\n#### Step 1: Setting Up the Spark Environment\n\nIn a real-world company setup, we wouldn\u2019t use Google Colab directly. Instead, we would:\n\n1. **Deploy a Spark Cluster** (like AWS EMR, GCP Dataproc, or an on-prem Hadoop cluster, Azure HD Insight).\n\n2. **Store Data in HDFS** instead of local storage.\n    > Load data from Kaggle i.e., [Data Source](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce \"click the link to go to kaggle\")  \n    >  ```bash\n    > !curl -L -o ~/olist/brazilian-ecommerce.zip https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce\n    >```\n    \n    > Unzip the file  \n    > ```bash\n    > !unzip brazilian-ecommerce.zip -d ~/olist/data/\n    > ```\n     <br>\n3. **Use PySpark** to interact with data."}, {"cell_type": "code", "execution_count": 8, "id": "0c50e9bb-5cff-42cb-9d2b-1dd71d218b5f", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 42.6M  100 42.6M    0     0  68.9M      0 --:--:-- --:--:-- --:--:-- 68.9M\n"}], "source": "#!/bin/bash\n!curl -L -o /data/brazilian-ecommerce.zip https://www.kaggle.com/api/v1/datasets/download/olistbr/brazilian-ecommerce"}, {"cell_type": "code", "execution_count": 10, "id": "c2dab040-9498-435e-8045-8bf166b85b23", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Archive:  /data/brazilian-ecommerce.zip\n  inflating: /data/brazilian_ecommerce/olist_customers_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_geolocation_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_order_items_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_order_payments_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_order_reviews_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_orders_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_products_dataset.csv  \n  inflating: /data/brazilian_ecommerce/olist_sellers_dataset.csv  \n  inflating: /data/brazilian_ecommerce/product_category_name_translation.csv  \n"}], "source": "!unzip /data/brazilian-ecommerce.zip -d /data/brazilian_ecommerce"}, {"cell_type": "code", "execution_count": 13, "id": "70f7a8d5-a907-4459-9f9c-af73cfa2dcb9", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "total 121M\n-rw-r--r-- 1 root root 171K Oct  1  2021 olist_sellers_dataset.csv\n-rw-r--r-- 1 root root 2.6K Oct  1  2021 product_category_name_translation.csv\n-rw-r--r-- 1 root root 2.3M Oct  1  2021 olist_products_dataset.csv\n-rw-r--r-- 1 root root  14M Oct  1  2021 olist_order_reviews_dataset.csv\n-rw-r--r-- 1 root root  17M Oct  1  2021 olist_orders_dataset.csv\n-rw-r--r-- 1 root root 5.6M Oct  1  2021 olist_order_payments_dataset.csv\n-rw-r--r-- 1 root root  15M Oct  1  2021 olist_order_items_dataset.csv\n-rw-r--r-- 1 root root  59M Oct  1  2021 olist_geolocation_dataset.csv\n-rw-r--r-- 1 root root 8.7M Oct  1  2021 olist_customers_dataset.csv\n"}], "source": "! ls -lth /data/brazilian_ecommerce"}, {"cell_type": "code", "execution_count": 16, "id": "94a218b6-1ed7-459c-b109-ce7170a1637e", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [], "source": "!hadoop fs -put /data/brazilian_ecommerce/*.csv /tmp/olist/"}, {"cell_type": "code", "execution_count": 21, "id": "2e2efa06-cbcf-4927-b1b4-bd34b541bed0", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Found 9 items\n-rw-r--r--   2 root hadoop      8.6 M 2025-10-08 11:25 /tmp/olist/olist_customers_dataset.csv\n-rw-r--r--   2 root hadoop     58.4 M 2025-10-08 11:25 /tmp/olist/olist_geolocation_dataset.csv\n-rw-r--r--   2 root hadoop     14.7 M 2025-10-08 11:25 /tmp/olist/olist_order_items_dataset.csv\n-rw-r--r--   2 root hadoop      5.5 M 2025-10-08 11:25 /tmp/olist/olist_order_payments_dataset.csv\n-rw-r--r--   2 root hadoop     13.8 M 2025-10-08 11:25 /tmp/olist/olist_order_reviews_dataset.csv\n-rw-r--r--   2 root hadoop     16.8 M 2025-10-08 11:25 /tmp/olist/olist_orders_dataset.csv\n-rw-r--r--   2 root hadoop      2.3 M 2025-10-08 11:25 /tmp/olist/olist_products_dataset.csv\n-rw-r--r--   2 root hadoop    170.6 K 2025-10-08 11:25 /tmp/olist/olist_sellers_dataset.csv\n-rw-r--r--   2 root hadoop      2.6 K 2025-10-08 11:25 /tmp/olist/product_category_name_translation.csv\n"}], "source": "!hadoop fs -ls -h /tmp/olist"}, {"cell_type": "markdown", "id": "1e2f2ce3-49ba-4a4b-965b-939396eb1d5a", "metadata": {"tags": []}, "source": "#### Exploration of Datasets"}, {"cell_type": "code", "execution_count": 1, "id": "7660d710-1e5a-42ea-a083-3062a6b628dc", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/10/09 08:46:41 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n25/10/09 08:46:41 INFO SparkEnv: Registering MapOutputTracker\n25/10/09 08:46:41 INFO SparkEnv: Registering BlockManagerMaster\n25/10/09 08:46:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n25/10/09 08:46:41 INFO SparkEnv: Registering OutputCommitCoordinator\n"}, {"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-bb46-m.us-central1-a.c.calcium-firefly-470211-k4.internal:46565\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.3</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>First_stage</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f967e3d7610>"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql import SparkSession\nspark = SparkSession.builder.\\\nappName(\"First_stage\").getOrCreate()\nspark"}, {"cell_type": "code", "execution_count": 2, "id": "03941884-1813-42fc-a565-3fdf51eb0b79", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "hdfs_path = \"/tmp/olist/\"\ncustomers = spark.read.csv(hdfs_path+\"olist_customers_dataset.csv\", header = \"true\", inferSchema = \"true\") "}, {"cell_type": "code", "execution_count": 3, "id": "809f9f98-5713-46b3-9a9d-9baea164f325", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+------------------------+--------------------+--------------+\n|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n+--------------------+--------------------+------------------------+--------------------+--------------+\n|06b8999e2fba1a1fb...|861eff4711a542e4b...|                   14409|              franca|            SP|\n|18955e83d337fd6b2...|290c77bc529b7ac93...|                    9790|sao bernardo do c...|            SP|\n|4e7b3e00288586ebd...|060e732b5b29e8181...|                    1151|           sao paulo|            SP|\n|b2b6027bc5c5109e5...|259dac757896d24d7...|                    8775|     mogi das cruzes|            SP|\n|4f2d8ab171c80ec83...|345ecd01c38d18a90...|                   13056|            campinas|            SP|\n+--------------------+--------------------+------------------------+--------------------+--------------+\nonly showing top 5 rows\n\n"}], "source": "customers.show(5)"}, {"cell_type": "code", "execution_count": 4, "id": "6b7e4ebb-1e00-4cd3-8f1f-95a1b930eba7", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- customer_id: string (nullable = true)\n |-- customer_unique_id: string (nullable = true)\n |-- customer_zip_code_prefix: integer (nullable = true)\n |-- customer_city: string (nullable = true)\n |-- customer_state: string (nullable = true)\n\n"}], "source": "customers.printSchema()"}, {"cell_type": "code", "execution_count": 5, "id": "6cbdba6a-626c-4a11-99c2-241807f096f2", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "orders = spark.read.csv(hdfs_path+\"olist_orders_dataset.csv\", header = \"true\", inferSchema = \"true\") \norder_items = spark.read.csv(hdfs_path+\"olist_order_items_dataset.csv\", header = \"true\", inferSchema = \"true\") \npayments = spark.read.csv(hdfs_path+\"olist_order_payments_dataset.csv\", header = \"true\", inferSchema = \"true\") \ngeo_location = spark.read.csv(hdfs_path+\"olist_geolocation_dataset.csv\", header = \"true\", inferSchema = \"true\") \nreviews = spark.read.csv(hdfs_path+\"olist_order_reviews_dataset.csv\", header = \"true\", inferSchema = \"true\") \nproducts = spark.read.csv(hdfs_path+\"olist_products_dataset.csv\", header = \"true\", inferSchema = \"true\") \nsellers = spark.read.csv(hdfs_path+\"olist_sellers_dataset.csv\", header = \"true\", inferSchema = \"true\") \nproduct_category = spark.read.csv(hdfs_path+\"product_category_name_translation.csv\", header = \"true\", inferSchema = \"true\") "}, {"cell_type": "code", "execution_count": 6, "id": "e0b8b8dd-4be3-41cd-81bb-b5d263431ba8", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+------------------+------------+--------------------+-------------+\n|            order_id|payment_sequential|payment_type|payment_installments|payment_value|\n+--------------------+------------------+------------+--------------------+-------------+\n|b81ef226f3fe1789b...|                 1| credit_card|                   8|        99.33|\n|a9810da82917af2d9...|                 1| credit_card|                   1|        24.39|\n|25e8ea4e93396b6fa...|                 1| credit_card|                   1|        65.71|\n|ba78997921bbcdc13...|                 1| credit_card|                   8|       107.78|\n|42fdf880ba16b47b5...|                 1| credit_card|                   2|       128.45|\n+--------------------+------------------+------------+--------------------+-------------+\nonly showing top 5 rows\n\nroot\n |-- order_id: string (nullable = true)\n |-- payment_sequential: integer (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- payment_installments: integer (nullable = true)\n |-- payment_value: double (nullable = true)\n\n"}], "source": "payments.show(5)\npayments.printSchema()"}, {"cell_type": "markdown", "id": "50a5c642-41ba-4f44-9c80-aa618e02880d", "metadata": {"tags": []}, "source": "#### Data Leakage - verifying with kaggle"}, {"cell_type": "code", "execution_count": 8, "id": "008004f1-39ce-4366-8e6b-a50334d7ea96", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"data": {"text/plain": "99441"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "customers.count()"}, {"cell_type": "code", "execution_count": 10, "id": "49586bc5-13a1-4d1a-a6e2-306c9234fba5", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "99441\n103886\n112650\n104162\n"}], "source": "print(orders.count())\nprint(payments.count())\nprint(order_items.count())\nprint(reviews.count())"}, {"cell_type": "markdown", "id": "d2017415-0c8f-4282-90fa-b2903b3c7e4b", "metadata": {"tags": []}, "source": "#### Checking for Null values in dataframes"}, {"cell_type": "code", "execution_count": 19, "id": "32226250-1d6e-43cc-9feb-8fe0976cdbb4", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+------------------+------------------------+-------------+--------------+\n|customer_id|customer_unique_id|customer_zip_code_prefix|customer_city|customer_state|\n+-----------+------------------+------------------------+-------------+--------------+\n|          0|                 0|                       0|            0|             0|\n+-----------+------------------+------------------------+-------------+--------------+\n\n"}], "source": "# null values count in each column\nfrom pyspark.sql.functions import col, when, count\ncustomers.select([count(when(customers[i].isNull(),1)).alias(i) for i in customers.columns]).show()"}, {"cell_type": "code", "execution_count": 20, "id": "c07cb7eb-967d-4ed0-ba07-1a6d6b7ccd24", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+-----------+------------+------------------------+-----------------+----------------------------+-----------------------------+-----------------------------+\n|order_id|customer_id|order_status|order_purchase_timestamp|order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|\n+--------+-----------+------------+------------------------+-----------------+----------------------------+-----------------------------+-----------------------------+\n|       0|          0|           0|                       0|              160|                        1783|                         2965|                            0|\n+--------+-----------+------------+------------------------+-----------------+----------------------------+-----------------------------+-----------------------------+\n\n"}], "source": "orders.select([count(when(col(i).isNull(),1)).alias(i) for i in orders.columns]).show()"}, {"cell_type": "code", "execution_count": 21, "id": "953850c1-e273-4b9e-8920-b3b69a558dc1", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+------------------+------------+--------------------+-------------+\n|order_id|payment_sequential|payment_type|payment_installments|payment_value|\n+--------+------------------+------------+--------------------+-------------+\n|       0|                 0|           0|                   0|            0|\n+--------+------------------+------------+--------------------+-------------+\n\n"}], "source": "payments.select([count(when(col(i).isNull(),1)).alias(i) for i in payments.columns]).show()"}, {"cell_type": "markdown", "id": "66e54135-5b00-45f6-8641-128f62538874", "metadata": {}, "source": "#### Checking for duplicate values"}, {"cell_type": "code", "execution_count": 24, "id": "b93d8307-0123-4c96-9b17-3bd2548c4fcb", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-----------+-----+\n|customer_id|count|\n+-----------+-----+\n+-----------+-----+\n\n"}], "source": "customers.groupBy(\"customer_id\").count().filter(\"count>1\").show()"}, {"cell_type": "code", "execution_count": 25, "id": "7a3be812-fd79-4130-811f-c164175f2bce", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}, "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------+-----+\n|order_id|count|\n+--------+-----+\n+--------+-----+\n\n"}], "source": "orders.groupBy(\"order_id\").count().filter(\"count>1\").show()"}, {"cell_type": "code", "execution_count": null, "id": "18c2e603-c887-426b-8a82-a221eb787f07", "metadata": {"collapsed": true, "jupyter": {"outputs_hidden": true}}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.13"}}, "nbformat": 4, "nbformat_minor": 5}